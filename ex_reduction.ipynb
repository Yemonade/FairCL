{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "sys.path.append('D:\\\\Compute Science\\\\Machine Learning\\\\论文\\\\项目\\\\FairSPL\\\\venv_torch')\n",
    "sys.path.append('D:\\\\Compute Science\\\\Machine Learning\\\\论文\\\\项目\\\\FairSPL\\\\venv_torch\\\\lib\\\\site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from dataset import fetch_data\n",
    "from models.AdversarialDebiasing import AdversarialDebiasing\n",
    "from eval import Evaluator\n",
    "from utils import get_curriculum_stages\n",
    "# from tmp.AdversarialDebiasing_copied2_before_lr import AdversarialDebiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Adult dataset..\n",
      "train_val_df.shape:  (32561, 14)\n",
      "test_df.shape:  (12661, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset statistic - #total: 45222; #train: 26049; #val.: 6512; #test: 12661; #dim.: 95\n",
      "\n",
      "data.x_train.shape:  (26049, 95)\n",
      "data.x_test.shape:  (12661, 95)\n",
      "========== before train ==========\n",
      "========== Results on origin ==========\n",
      "Grp. 0 - #instance: 8460; #pos : 954\n",
      "Grp. 1 - #instance: 17589; #pos : 5496\n",
      "Demographic parity: 0.199702; Equal opportunity: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data = fetch_data(\"adult\")\n",
    "print(\"data.x_train.shape: \", data.x_train.shape)\n",
    "print(\"data.x_test.shape: \", data.x_test.shape)\n",
    "origin_evaluator, train_evaluator, test_evaluator = Evaluator(data.s_train, \"origin\"), Evaluator(data.s_train,\n",
    "                                                                                                 \"train\"), Evaluator(\n",
    "    data.s_test, \"test\")\n",
    "if data.s_val is not None:\n",
    "    val_evaluator = Evaluator(data.s_val, \"val\")\n",
    "\n",
    "n_features, n_classes, n_groups = data.x_train.shape[1], len(np.unique(data.y_train)), len(np.unique(data.s_train))\n",
    "if n_classes == 2:\n",
    "    n_classes = 1\n",
    "if n_groups == 2:\n",
    "    n_groups = 1\n",
    "\n",
    "print(\"========== before train ==========\")\n",
    "origin_res = origin_evaluator(data.y_train, no_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total step:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExponentiatedGradient(constraints=<fairlearn.reductions._moments.utility_parity.DemographicParity object at 0x00000239440156C8>,\n",
       "                      estimator=GradientBoostingClassifier(random_state=0),\n",
       "                      nu=0.0010570582632976704)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "dp = DemographicParity(difference_bound=0.001)\n",
    "reduction = ExponentiatedGradient(classifier, dp)\n",
    "\n",
    "reduction.fit(data.x_train, data.y_train, sensitive_features=data.s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== after train(without debiasing) ==========\n",
      "========== Results on train ==========\n",
      "Grp. 0 - #instance: 8460; #pos. pred: 1355; Acc.: 0.904137\n",
      "Grp. 1 - #instance: 17589; #pos. pred: 2853; Acc.: 0.815510\n",
      "Overall acc.: 0.844293; Demographic parity: 0.002038; Equal opportunity: 0.320778\n",
      "========== Results on test ==========\n",
      "Grp. 0 - #instance: 4147; #pos. pred: 652; Acc.: 0.895105\n",
      "Grp. 1 - #instance: 8514; #pos. pred: 1323; Acc.: 0.809725\n",
      "Overall acc.: 0.837691; Demographic parity: 0.001831; Equal opportunity: 0.285915\n"
     ]
    }
   ],
   "source": [
    "print(\"========== after train(without debiasing) ==========\")\n",
    "pred_label_train = reduction.predict(data.x_train)\n",
    "train_res = train_evaluator(data.y_train, pred_label_train, no_train=False)\n",
    "\n",
    "pred_label_test = reduction.predict(data.x_test)\n",
    "test_res = test_evaluator(data.y_test, pred_label_test, no_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "g:0, y:0 ==> size:2502\n",
      "g:0, y:1 ==> size:318\n",
      "g:1, y:0 ==> size:4031\n",
      "g:1, y:1 ==> size:1832\n",
      "====================\n",
      "g:0, y:0 ==> size:2502\n",
      "g:0, y:1 ==> size:318\n",
      "g:1, y:0 ==> size:4031\n",
      "g:1, y:1 ==> size:1832\n",
      "====================\n",
      "g:0, y:0 ==> size:2502\n",
      "g:0, y:1 ==> size:318\n",
      "g:1, y:0 ==> size:4031\n",
      "g:1, y:1 ==> size:1832\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "stages = get_curriculum_stages(data.y_train, data.s_train, 'data/adult/sorted_idx_%d.json' % data.num_val, N=N)\n",
    "# 从难到易\n",
    "# stages.reverse()\n",
    "# 并集\n",
    "# new_stages = []\n",
    "# for i in range(len(stages) - 1, 0, -1):\n",
    "#     new_stages.append(np.concatenate([stages[i], stages[i - 1]]))\n",
    "\n",
    "# new_stages.append(stages[0])\n",
    "# new_stages.reverse()\n",
    "# base_epoch = 500\n",
    "# epoch_list = [int(base_epoch / i) for i in range(1,N+1)]\n",
    "# epoch_list.reverse()\n",
    "\n",
    "new_stages = [stages[0]]\n",
    "for i in range(1, len(stages)):\n",
    "    new_stages.append(np.concatenate([stages[i], new_stages[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8683\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "data can be loaded only once",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_41696\\2563462637.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0my_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mstage\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[0ms_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0ms_train\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mstage\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mreduction_cl\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msensitive_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0ms_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\fairlearn\\reductions\\_exponentiated_gradient\\exponentiated_gradient.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m                                  \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstraints\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mB\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m                                  \u001B[0msample_weight_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msample_weight_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m                                  **kwargs)\n\u001B[0m\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[0mtheta\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlagrangian\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstraints\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\fairlearn\\reductions\\_exponentiated_gradient\\_lagrangian.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, X, y, estimator, constraints, B, opt_lambda, sample_weight_name, **kwargs)\u001B[0m\n\u001B[0;32m     47\u001B[0m                  sample_weight_name='sample_weight', **kwargs):\n\u001B[0;32m     48\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstraints\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstraints\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstraints\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstraints\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdefault_objective\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py\u001B[0m in \u001B[0;36mload_data\u001B[1;34m(self, X, y, sensitive_features, control_features)\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[0mbase_event\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0m_ALL\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m         \u001B[0mevent\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_merge_event_and_control_columns\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_event\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcf_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 315\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msensitive_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msf_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    316\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\fairlearn\\reductions\\_moments\\utility_parity.py\u001B[0m in \u001B[0;36mload_data\u001B[1;34m(self, X, y, sensitive_features, event, utilities)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    139\u001B[0m         \"\"\"\n\u001B[1;32m--> 140\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msensitive_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msensitive_features\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    141\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtags\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0m_EVENT\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mutilities\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\fairlearn\\reductions\\_moments\\moment.py\u001B[0m in \u001B[0;36mload_data\u001B[1;34m(self, X, y, sensitive_features)\u001B[0m\n\u001B[0;32m     42\u001B[0m         \"\"\"\n\u001B[0;32m     43\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_loaded\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[1;34m\"data can be loaded only once\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0msensitive_features\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[1;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msensitive_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: data can be loaded only once"
     ]
    }
   ],
   "source": [
    "# CL test\n",
    "reduction_cl = ExponentiatedGradient(classifier, dp)\n",
    "start = datetime.datetime.now()\n",
    "for stage  in new_stages:\n",
    "    # TODO: try set1 U set2\n",
    "    print(len(stage))\n",
    "    x_train = data.x_train[stage, :]\n",
    "    y_train = data.y_train[stage]\n",
    "    s_train = data.s_train[stage]\n",
    "    reduction_cl.fit(x_train, y_train, sensitive_features=s_train)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print((end - start).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
