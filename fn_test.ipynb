{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "sys.path.append('D:\\\\Compute Science\\\\Machine Learning\\\\论文\\\\项目\\\\FairSPL\\\\venv_torch')\n",
    "sys.path.append('D:\\\\Compute Science\\\\Machine Learning\\\\论文\\\\项目\\\\FairSPL\\\\venv_torch\\\\lib\\\\site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3905e0a0cd294000a027991b481e2fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(range(10), ncols=70)\n",
    "for i in t:\n",
    "\tt.set_description(f\"hello: {i:0>3}\")\n",
    "\tt.write(f\"{i}\")  # 使用t.write代替print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json dump test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation([1,2,3])\n",
    "with open('./tmp/idx_test.json', 'w') as f:\n",
    "    json.dump(idx.tolist(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.where test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(5)\n",
    "np.where(arr > 2, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c   d\n",
       "0  4  6  1   5\n",
       "1  8  7  2  11\n",
       "2  0  3  9  10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 4, 8]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.permutation(np.arange(12)).reshape((3,-1)), columns=['a','b','c','d'])\n",
    "display(df)\n",
    "list(np.unique(df['a']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df, label_mapping):\n",
    "    label_mapping = {} if label_mapping is None else label_mapping\n",
    "    updated_label_mapping = {}\n",
    "    for c in df.columns:\n",
    "        if c in ['size', 'color']:\n",
    "            column = df[c]\n",
    "            df = df.drop(c, axis=1)\n",
    "\n",
    "            if c in label_mapping.keys():\n",
    "                mapping = label_mapping[c]\n",
    "            else:\n",
    "                unique_value = list(dict.fromkeys(column))\n",
    "                mapping = {v: i for i, v in enumerate(unique_value)}\n",
    "                updated_label_mapping[c] = mapping\n",
    "\n",
    "            n = len(mapping)\n",
    "            # directly apply mapping on the binary feature\n",
    "            if n <= 2:\n",
    "                df[c] = [mapping[e] for e in column]\n",
    "            # apply one hot on non-binary feature\n",
    "            else:\n",
    "                for i in range(n):\n",
    "                    column_name = '{}.{}'.format(c, i)\n",
    "                    df[column_name] = [1. if list(mapping.keys())[i] == e else 0. for e in column]\n",
    "\n",
    "    updated_label_mapping.update(label_mapping)\n",
    "    return df, updated_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>prize</th>\n",
       "      <th>class label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  prize class label\n",
       "0  green    M   10.1      class1\n",
       "1    red    L   13.5      class2\n",
       "2   blue   XL   15.3      class1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "            ['green', 'M', 10.1, 'class1'],\n",
    "            ['red', 'L', 13.5, 'class2'],\n",
    "            ['blue', 'XL', 15.3, 'class1']])\n",
    "\n",
    "df.columns = ['color', 'size', 'prize', 'class label']\n",
    "\n",
    "size_mapping = {\n",
    "    'size':\n",
    "        {\n",
    "           'XL': 3,\n",
    "           'L': 2,\n",
    "           'M': 1\n",
    "        }\n",
    "\n",
    "}\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   prize class label  color.0  color.1  color.2  size.0  size.1  size.2\n",
       " 0   10.1      class1      1.0      0.0      0.0     0.0     0.0     1.0\n",
       " 1   13.5      class2      0.0      1.0      0.0     0.0     1.0     0.0\n",
       " 2   15.3      class1      0.0      0.0      1.0     1.0     0.0     0.0,\n",
       " {'color': {'green': 0, 'red': 1, 'blue': 2},\n",
       "  'size': {'XL': 3, 'L': 2, 'M': 1}})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(df, size_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   color size  prize class label  color.0  color.1  color.2  size.0  size.1  \\\n",
       " 0  green    M   10.1      class1      1.0      0.0      0.0     0.0     0.0   \n",
       " 1    red    L   13.5      class2      0.0      1.0      0.0     0.0     1.0   \n",
       " 2   blue   XL   15.3      class1      0.0      0.0      1.0     1.0     0.0   \n",
       " \n",
       "    size.2  \n",
       " 0     1.0  \n",
       " 1     0.0  \n",
       " 2     0.0  ,\n",
       " {'color': {'green': 0, 'red': 1, 'blue': 2},\n",
       "  'size': {'XL': 3, 'L': 2, 'M': 1}})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(df, size_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aif360'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_18456\\1016883152.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Load all necessary packages\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0maif360\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mBinaryLabelDatasetMetric\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0maif360\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mClassificationMetric\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0maif360\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0malgorithms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim_preproc_helpers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_preproc_functions\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mload_preproc_data_adult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'aif360'"
     ]
    }
   ],
   "source": [
    "# Load all necessary packages\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "\n",
    "from aif360.algorithms.inprocessing.exponentiated_gradient_reduction import ExponentiatedGradientReduction\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOError: [Errno 2] No such file or directory: 'D:\\\\Compute Science\\\\Machine Learning\\\\论文\\\\项目\\\\FairSPL\\\\venv_torch\\\\lib\\\\site-packages\\\\aif360\\\\datasets\\\\..\\\\data\\\\raw\\\\adult\\\\adult.data'\n",
      "To use this class, please download the following files:\n",
      "\n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
      "\n",
      "and place them, as-is, in the folder:\n",
      "\n",
      "\tD:\\Compute Science\\Machine Learning\\论文\\项目\\FairSPL\\venv_torch\\lib\\site-packages\\aif360\\data\\raw\\adult\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Compute Science\\Machine Learning\\论文\\项目\\FairSPL\\venv_torch\\lib\\site-packages\\aif360\\datasets\\adult_dataset.py\", line 90, in __init__\n",
      "    skipinitialspace=True, na_values=na_values)\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 311, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 586, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 482, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 811, in __init__\n",
      "    self._engine = self._make_engine(self.engine)\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1040, in _make_engine\n",
      "    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 51, in __init__\n",
      "    self._open_handles(src, kwds)\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\", line 229, in _open_handles\n",
      "    errors=kwds.get(\"encoding_errors\", \"strict\"),\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\common.py\", line 707, in get_handle\n",
      "    newline=\"\",\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\Compute Science\\\\Machine Learning\\\\论文\\\\项目\\\\FairSPL\\\\venv_torch\\\\lib\\\\site-packages\\\\aif360\\\\datasets\\\\..\\\\data\\\\raw\\\\adult\\\\adult.data'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_3264\\2847682178.py\", line 2, in <module>\n",
      "    dataset_orig = load_preproc_data_adult()\n",
      "  File \"D:\\Compute Science\\Machine Learning\\论文\\项目\\FairSPL\\venv_torch\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\optim_preproc_helpers\\data_preproc_functions.py\", line 89, in load_preproc_data_adult\n",
      "    custom_preprocessing=custom_preprocessing)\n",
      "  File \"D:\\Compute Science\\Machine Learning\\论文\\项目\\FairSPL\\venv_torch\\lib\\site-packages\\aif360\\datasets\\adult_dataset.py\", line 103, in __init__\n",
      "    sys.exit(1)\n",
      "SystemExit: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"E:\\Environment\\python\\python3.7.4\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mD:\\Compute Science\\Machine Learning\\论文\\项目\\FairSPL\\venv_torch\\lib\\site-packages\\aif360\\datasets\\adult_dataset.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001B[0m\n\u001B[0;32m     89\u001B[0m             train = pd.read_csv(train_path, header=None, names=column_names,\n\u001B[1;32m---> 90\u001B[1;33m                 skipinitialspace=True, na_values=na_values)\n\u001B[0m\u001B[0;32m     91\u001B[0m             test = pd.read_csv(test_path, header=0, names=column_names,\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    228\u001B[0m             \u001B[0mstorage_options\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"storage_options\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 229\u001B[1;33m             \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"encoding_errors\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"strict\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    230\u001B[0m         )\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    706\u001B[0m                 \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 707\u001B[1;33m                 \u001B[0mnewline\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    708\u001B[0m             )\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:\\\\Compute Science\\\\Machine Learning\\\\论文\\\\项目\\\\FairSPL\\\\venv_torch\\\\lib\\\\site-packages\\\\aif360\\\\datasets\\\\..\\\\data\\\\raw\\\\adult\\\\adult.data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mSystemExit\u001B[0m                                Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3264\\2847682178.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Get the dataset and split into train and test\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mdataset_orig\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_preproc_data_adult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Compute Science\\Machine Learning\\论文\\项目\\FairSPL\\venv_torch\\lib\\site-packages\\aif360\\algorithms\\preprocessing\\optim_preproc_helpers\\data_preproc_functions.py\u001B[0m in \u001B[0;36mload_preproc_data_adult\u001B[1;34m(protected_attributes, sub_samp, balance)\u001B[0m\n\u001B[0;32m     88\u001B[0m                                 for x in D_features]},\n\u001B[1;32m---> 89\u001B[1;33m         custom_preprocessing=custom_preprocessing)\n\u001B[0m\u001B[0;32m     90\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Compute Science\\Machine Learning\\论文\\项目\\FairSPL\\venv_torch\\lib\\site-packages\\aif360\\datasets\\adult_dataset.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, label_name, favorable_classes, protected_attribute_names, privileged_classes, instance_weights_name, categorical_features, features_to_keep, features_to_drop, na_values, custom_preprocessing, metadata)\u001B[0m\n\u001B[0;32m    102\u001B[0m             \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 103\u001B[1;33m             \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mSystemExit\u001B[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2091\u001B[0m                            'the full traceback.\\n']\n\u001B[0;32m   2092\u001B[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001B[1;32m-> 2093\u001B[1;33m                                                                      value))\n\u001B[0m\u001B[0;32m   2094\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2095\u001B[0m                     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mget_exception_only\u001B[1;34m(self, etype, value)\u001B[0m\n\u001B[0;32m    752\u001B[0m         \u001B[0mvalue\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mexception\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    753\u001B[0m         \"\"\"\n\u001B[1;32m--> 754\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mListTB\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstructured_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    755\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    756\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mshow_exception_only\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, context)\u001B[0m\n\u001B[0;32m    631\u001B[0m                     chained_exceptions_tb_offset, context)\n\u001B[0;32m    632\u001B[0m                 \u001B[1;33m+\u001B[0m \u001B[0mchained_exception_message\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 633\u001B[1;33m                 + out_list)\n\u001B[0m\u001B[0;32m    634\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    635\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mout_list\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1367\u001B[0m         return FormattedTB.structured_traceback(\n\u001B[1;32m-> 1368\u001B[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[0m\u001B[0;32m   1369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1370\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1266\u001B[0m             \u001B[1;31m# Verbose modes need a full traceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1267\u001B[0m             return VerboseTB.structured_traceback(\n\u001B[1;32m-> 1268\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1269\u001B[0m             )\n\u001B[0;32m   1270\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'Minimal'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1123\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1124\u001B[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[1;32m-> 1125\u001B[1;33m                                                                tb_offset)\n\u001B[0m\u001B[0;32m   1126\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1127\u001B[0m         \u001B[0mcolors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mColors\u001B[0m  \u001B[1;31m# just a shorthand + quicker name lookup\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Environment\\python\\python3.7.4\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[1;34m(etype, value, records)\u001B[0m\n\u001B[0;32m    380\u001B[0m     \u001B[1;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m     \u001B[1;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "np.random.seed(0)\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Chunks Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_curriculum_stages\n",
    "import json\n",
    "from dataset import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Adult dataset..\n",
      "train_val_df.shape:  (32561, 15)\n",
      "test_df.shape:  (12661, 15)\n",
      "Dataset statistic - #total: 45222; #train: 26049; #val.: 6512; #test: 12661; #dim.: 102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Environment\\python\\python3.7.4\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "data = fetch_data(\"adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curriculum_stages(y, s, idx_path, N=2):\n",
    "    \"\"\" split the index into N shares in origin order.\n",
    "    Arguments:\n",
    "        idx_path(str): the index storage path\n",
    "        N(int): the number of stages\n",
    "\n",
    "    Return:\n",
    "\n",
    "    \"\"\"\n",
    "    with open(idx_path) as f:\n",
    "        idx = json.load(f)\n",
    "    idx = np.array(idx)\n",
    "    y_sorted = y[idx]\n",
    "    s_sorted = s[idx]\n",
    "    \n",
    "    classes = np.unique(y)\n",
    "    s_feat = np.unique(s)\n",
    "\n",
    "    # N = 2 时，就是每个 subgroup 按顺序取一半，放在一起\n",
    "    # step1: get the subgroup: {(g0, y0): [...]}\n",
    "    all_grp = {}\n",
    "    # step2: calculate each group size in one stage\n",
    "    grp_size = {}\n",
    "    # y \n",
    "    for g in s_feat:\n",
    "        for label in classes:\n",
    "            # order messy?\n",
    "            sub_grp = idx[(s_sorted == g) & (y_sorted == label)]\n",
    "            all_grp[(g, label)] = sub_grp\n",
    "            grp_size[(g, label)] = len(sub_grp) / N\n",
    "\n",
    "    res = []\n",
    "    for i in range(N):\n",
    "        tmp = []\n",
    "        print('='*20)\n",
    "        for g, label in all_grp.keys():\n",
    "            size = int(grp_size[(g, label)])\n",
    "            sub_grp = all_grp[(g, label)]\n",
    "            print(pd.Series(y[sub_grp]).value_counts())\n",
    "            j = i * size\n",
    "            print('g:%d, y:%d ==> size:%d' % (g,label,size))\n",
    "#             print('===> j: %d, j+size: %d, len: %d' % (j, j + size, len(sub_grp)))\n",
    "            tmp.append(sub_grp[j: j + size])\n",
    "        res.append(np.concatenate(tmp))\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "0.0    7506\n",
      "dtype: int64\n",
      "g:0, y:0 ==> size:3753\n",
      "1.0    954\n",
      "dtype: int64\n",
      "g:0, y:1 ==> size:477\n",
      "0.0    12093\n",
      "dtype: int64\n",
      "g:1, y:0 ==> size:6046\n",
      "1.0    5496\n",
      "dtype: int64\n",
      "g:1, y:1 ==> size:2748\n",
      "====================\n",
      "0.0    7506\n",
      "dtype: int64\n",
      "g:0, y:0 ==> size:3753\n",
      "1.0    954\n",
      "dtype: int64\n",
      "g:0, y:1 ==> size:477\n",
      "0.0    12093\n",
      "dtype: int64\n",
      "g:1, y:0 ==> size:6046\n",
      "1.0    5496\n",
      "dtype: int64\n",
      "g:1, y:1 ==> size:2748\n"
     ]
    }
   ],
   "source": [
    "res = get_curriculum_stages(data.y_train, data.s_train, \"data/adult/sorted_idx_6512.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = res[0]\n",
    "x_train = data.x_train[stage, :]\n",
    "y_train = data.y_train[stage]\n",
    "s_train = data.s_train[stage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26049, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'y': data.y_train, 's': data.s_train})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s    y  \n",
       "1.0  0.0    12093\n",
       "0.0  0.0     7506\n",
       "1.0  1.0     5496\n",
       "0.0  1.0      954\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['s','y']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    7048\n",
       "0.0    5976\n",
       "Name: s, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['s'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
